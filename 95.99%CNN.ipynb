{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ecf90bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2 as cv\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import pickle\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from glob import glob \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d919234",
   "metadata": {},
   "source": [
    "Some learning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d36ddddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_CHANNELS = 3\n",
    "#TRAIN_SIZE=80000\n",
    "TRAIN_SIZE = 80000\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf5c24c",
   "metadata": {},
   "source": [
    "Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97caf6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130908\n",
       "1     89117\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I used cropped images\n",
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "train_labels['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3cb32a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.594969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.405031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0  0.594969\n",
       "1  0.405031"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_labels.label.value_counts() / len(train_labels)).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4775bf57",
   "metadata": {},
   "source": [
    "Balancing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40168315",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg = train_labels[train_labels['label']==0].sample(TRAIN_SIZE,random_state=45)\n",
    "train_pos = train_labels[train_labels['label']==1].sample(TRAIN_SIZE,random_state=45)\n",
    "\n",
    "train_data = pd.concat([train_neg, train_pos], axis=0).reset_index(drop=True)\n",
    "\n",
    "train_data = shuffle(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d35fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    80000\n",
       "0    80000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c97a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_ext(fn):\n",
    "    return fn+\".tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20859e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128000, 2)\n",
      "(32000, 2)\n"
     ]
    }
   ],
   "source": [
    "y = train_data['label']\n",
    "train_df, valid_df = train_test_split(train_data, test_size=0.2, random_state=45, stratify=y)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9adaf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46754</th>\n",
       "      <td>c6a2cdf3f07006fe0fbdbfb6190266e9d1925713.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57220</th>\n",
       "      <td>6618673bfdab59be5b0dcba933d3f69fa9c6edf4.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45963</th>\n",
       "      <td>9ab64d68ba53d76109a69dd8411af804cec8aa2a.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136712</th>\n",
       "      <td>b2c030b7fd8bdf0de595b352f5048ea8385fcdb2.tif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109273</th>\n",
       "      <td>36aa27a41fae246de8e18b695ebe7876f2647a39.tif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label\n",
       "46754   c6a2cdf3f07006fe0fbdbfb6190266e9d1925713.tif      0\n",
       "57220   6618673bfdab59be5b0dcba933d3f69fa9c6edf4.tif      0\n",
       "45963   9ab64d68ba53d76109a69dd8411af804cec8aa2a.tif      0\n",
       "136712  b2c030b7fd8bdf0de595b352f5048ea8385fcdb2.tif      1\n",
       "109273  36aa27a41fae246de8e18b695ebe7876f2647a39.tif      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['id'] = train_df['id'].apply(append_ext)\n",
    "valid_df['id'] = valid_df['id'].apply(append_ext)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1b76c",
   "metadata": {},
   "source": [
    "Image generator that load images in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a80fa3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29809c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 128000 validated image filenames belonging to 2 classes.\n",
      "Found 32000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_path = './train'\n",
    "train_df['label'] = train_df['label'].astype(str)\n",
    "valid_df['label'] = valid_df['label'].astype(str)\n",
    "\n",
    "train_loader = train_datagen.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    directory = train_path,\n",
    "    x_col = 'id',\n",
    "    y_col = 'label',\n",
    "    batch_size = BATCH_SIZE,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = (96,96)\n",
    ")\n",
    "\n",
    "valid_loader = valid_datagen.flow_from_dataframe(\n",
    "    dataframe = valid_df,\n",
    "    directory = train_path,\n",
    "    x_col = 'id',\n",
    "    y_col = 'label',\n",
    "    batch_size = BATCH_SIZE,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = (96,96)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6036ed6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "TR_STEPS = len(train_loader)\n",
    "VA_STEPS = len(valid_loader)\n",
    "\n",
    "print(TR_STEPS)\n",
    "print(VA_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6c605ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential([\n",
    "    Conv2D(32, (3,3), activation = 'relu', padding = 'same', input_shape=(96,96,3)),\n",
    "    Conv2D(32, (3,3), activation = 'relu', padding = 'same'),\n",
    "    Conv2D(32, (3,3), activation = 'relu', padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n",
    "    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n",
    "    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n",
    "    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n",
    "    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Dropout(0.4),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n",
    "    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n",
    "    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Flatten(),\n",
    "     Dense(128, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c51f8a",
   "metadata": {},
   "source": [
    "Round one training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f105a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(0.001)\n",
    "cnn.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5176f16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x288cf2c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x288cf2c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.4220 - accuracy: 0.8128 - auc_1: 0.8865WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2e7326550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2e7326550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2000/2000 [==============================] - 1620s 810ms/step - loss: 0.4220 - accuracy: 0.8128 - auc_1: 0.8866 - val_loss: 0.5587 - val_accuracy: 0.7523 - val_auc_1: 0.8412\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 2432s 1s/step - loss: 0.3116 - accuracy: 0.8695 - auc_1: 0.9405 - val_loss: 1.4592 - val_accuracy: 0.6601 - val_auc_1: 0.7304\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 4352s 2s/step - loss: 0.2579 - accuracy: 0.8943 - auc_1: 0.9593 - val_loss: 1.4309 - val_accuracy: 0.5893 - val_auc_1: 0.6100\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 2364s 1s/step - loss: 0.2253 - accuracy: 0.9102 - auc_1: 0.9688 - val_loss: 1.5297 - val_accuracy: 0.6538 - val_auc_1: 0.6383\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1950s 975ms/step - loss: 0.2012 - accuracy: 0.9214 - auc_1: 0.9748 - val_loss: 0.3289 - val_accuracy: 0.8629 - val_auc_1: 0.9435\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 5112s 3s/step - loss: 0.1871 - accuracy: 0.9277 - auc_1: 0.9783 - val_loss: 1.1175 - val_accuracy: 0.7435 - val_auc_1: 0.7893\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 5261s 3s/step - loss: 0.1723 - accuracy: 0.9335 - auc_1: 0.9813 - val_loss: 0.5504 - val_accuracy: 0.7995 - val_auc_1: 0.8825\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1963s 981ms/step - loss: 0.1623 - accuracy: 0.9385 - auc_1: 0.9833 - val_loss: 0.2727 - val_accuracy: 0.9047 - val_auc_1: 0.9601\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 2086s 1s/step - loss: 0.1581 - accuracy: 0.9392 - auc_1: 0.9842 - val_loss: 1.0428 - val_accuracy: 0.7345 - val_auc_1: 0.7823\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 2134s 1s/step - loss: 0.1493 - accuracy: 0.9433 - auc_1: 0.9859 - val_loss: 0.2472 - val_accuracy: 0.9033 - val_auc_1: 0.9632\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 2209s 1s/step - loss: 0.1204 - accuracy: 0.9548 - auc_1: 0.9906 - val_loss: 0.1209 - val_accuracy: 0.9564 - val_auc_1: 0.9903\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 2026s 1s/step - loss: 0.1134 - accuracy: 0.9577 - auc_1: 0.9915 - val_loss: 0.1583 - val_accuracy: 0.9389 - val_auc_1: 0.9848\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 4998s 2s/step - loss: 0.1099 - accuracy: 0.9595 - auc_1: 0.9920 - val_loss: 0.1959 - val_accuracy: 0.9308 - val_auc_1: 0.9784\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 4507s 2s/step - loss: 0.1063 - accuracy: 0.9613 - auc_1: 0.9925 - val_loss: 0.4326 - val_accuracy: 0.8586 - val_auc_1: 0.9289\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 4530s 2s/step - loss: 0.1057 - accuracy: 0.9610 - auc_1: 0.9925 - val_loss: 0.1465 - val_accuracy: 0.9427 - val_auc_1: 0.9865\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 4694s 2s/step - loss: 0.1035 - accuracy: 0.9622 - auc_1: 0.9928 - val_loss: 0.1103 - val_accuracy: 0.9599 - val_auc_1: 0.9914\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 4654s 2s/step - loss: 0.0999 - accuracy: 0.9632 - auc_1: 0.9933 - val_loss: 0.1287 - val_accuracy: 0.9535 - val_auc_1: 0.9888\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 9352s 5s/step - loss: 0.0997 - accuracy: 0.9634 - auc_1: 0.9932 - val_loss: 0.1545 - val_accuracy: 0.9403 - val_auc_1: 0.9856\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 2191s 1s/step - loss: 0.0979 - accuracy: 0.9647 - auc_1: 0.9935 - val_loss: 0.1189 - val_accuracy: 0.9570 - val_auc_1: 0.9903\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 2367s 1s/step - loss: 0.0950 - accuracy: 0.9651 - auc_1: 0.9938 - val_loss: 0.1929 - val_accuracy: 0.9237 - val_auc_1: 0.9796\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 2297s 1s/step - loss: 0.0921 - accuracy: 0.9665 - auc_1: 0.9941 - val_loss: 0.1310 - val_accuracy: 0.9500 - val_auc_1: 0.9890\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 2737s 1s/step - loss: 0.0908 - accuracy: 0.9669 - auc_1: 0.9944 - val_loss: 0.1233 - val_accuracy: 0.9539 - val_auc_1: 0.9900\n",
      "Epoch 3/10\n",
      "  10/2000 [..............................] - ETA: 1:08:06 - loss: 0.0975 - accuracy: 0.9641 - auc_1: 0.9937"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p9/vc2rh8cd5p1gwtsshmkr0zdw0000gn/T/ipykernel_93341/3721012556.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m h3 = cnn.fit(\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTR_STEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h1 = cnn.fit(\n",
    "    x = train_loader, \n",
    "    steps_per_epoch = TR_STEPS, \n",
    "    epochs = 10,\n",
    "    validation_data = valid_loader, \n",
    "    validation_steps = VA_STEPS, \n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "tf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.0001)\n",
    "\n",
    "h2 = cnn.fit(\n",
    "    x = train_loader, \n",
    "    steps_per_epoch = TR_STEPS, \n",
    "    epochs = 10,\n",
    "    validation_data = valid_loader, \n",
    "    validation_steps = VA_STEPS, \n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "tf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.00001)\n",
    "\n",
    "\n",
    "h3 = cnn.fit(\n",
    "    x = train_loader, \n",
    "    steps_per_epoch = TR_STEPS, \n",
    "    epochs = 10,\n",
    "    validation_data = valid_loader, \n",
    "    validation_steps = VA_STEPS, \n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647c852b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
